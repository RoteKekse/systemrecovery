{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamical System Approximation\n",
    "This notebook aims at learning a functional correlation based on given snapshots. The data is created through the following ODE which is called the Fermi Pasta model:\n",
    "\\begin{align}\n",
    "\\frac{d^2}{dt^2} x_i = (x_{i+1} - 2x_i + x_{i-1}) + 0.7((x_{i+1} - x_i)^3 - (x_i-x_{i-1})^3) + \\mathcal{N}(0,\\sigma)\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.4f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xerus\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import time \n",
    "from itertools import chain\n",
    "import helpers as hp\n",
    "import pandas as pd\n",
    "\n",
    "%precision  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction of the exact solution in the choosen basis.\n",
    "#Transform implements the basis transformation for given b\n",
    "#For the exact solution we also factor out the kernel, by use of the Pseudoinverse.\n",
    "def transform(X):\n",
    "    M = np.zeros([4,4])\n",
    "    M[0,0] = 1   #1\n",
    "    M[1,1] = 1   #1\n",
    "    M[2,2] = 1.5 #1.5\n",
    "    M[3,3] = 2.5 #2.5\n",
    "    M[0,2] = -0.5 #-0.5\n",
    "    M[1,3] = -1.5 #-1.5\n",
    "    t = xerus.Tensor.from_ndarray(np.linalg.inv(M))\n",
    "    a1,a2,a3,a4,b1,b2,b3,b4 = xerus.indices(8)\n",
    "    for eq in range(noo):\n",
    "        tmp = X.get_component(eq)\n",
    "        tmp2 = C2list[eq]\n",
    "        tmp(a1,a2,a3,a4) <<  tmp(a1,b2,a3,a4)* t(a2,b2) \n",
    "        X.set_component(eq,tmp)\n",
    "    return X\n",
    "\n",
    "def project(X):\n",
    "    dim = ([(3 if i == 0 or i == noo -1 else 4) for i in range(0,noo)])\n",
    "    dim.extend(dim)\n",
    "    C2T = xerus.TTOperator(dim)    \n",
    "    for eq in range(noo):\n",
    "        idx = [0 for i in range(noo)]\n",
    "        if eq == 0:\n",
    "            idx[0] = 2\n",
    "            idx[1] = 3\n",
    "        elif eq == noo -1:\n",
    "            idx[noo-2] = 1\n",
    "            idx[noo-1] = 1\n",
    "        elif eq == noo -2:\n",
    "            idx[eq-1] = 1\n",
    "            idx[eq]   = 2\n",
    "            idx[eq+1] = 2\n",
    "        else:\n",
    "            idx[eq-1] = 1\n",
    "            idx[eq]   = 2\n",
    "            idx[eq+1] = 3\n",
    "        idx.extend(idx)\n",
    "        C2T += xerus.TTOperator.dirac(dim,idx) \n",
    "    C2T.round(1e-12)\n",
    "    i1,i2,i3,i4,i5,i6,j1,j2,j3,j4,k1,k2,k3 = xerus.indices(13)\n",
    "\n",
    "    X(i1^noo,j1^noo) << X(i1^noo,k1^noo) * C2T(k1^noo,j1^noo)\n",
    "    X.round(1e-12)\n",
    "    return X\n",
    "\n",
    "def exact(noo,p):\n",
    "    beta = 0.7\n",
    "    C1ex = hp.construct_exact_fermit_pasta(noo,p,beta)\n",
    "    C1ex = transform(C1ex)  \n",
    "    C1ex = project(C1ex) \n",
    "    return C1ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery algorithm\n",
    "We want to recover the exact solution with the help of a regularized ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize simulation\n",
    "def initialize(p,noo):\n",
    "    rank = 4 #fix rank\n",
    "    dim = [p for i in range(0,noo)]\n",
    "    dim.extend([4 for i in range(0,noo)])\n",
    "    dim[noo] = 3\n",
    "    dim[2*noo-1]=3\n",
    "    C = xerus.TTOperator.random(dim,[rank for i in range(0,noo-1)]) # initalize randomly\n",
    "    C.move_core(0,True)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "d   m     sigma  runs\n",
       "12  4500  0.01   0       0.0\n",
       "                 1       0.0\n",
       "                 2       0.0\n",
       "          0.10   0       0.0\n",
       "                 1       0.0\n",
       "                 2       0.0\n",
       "          1.00   0       0.0\n",
       "                 1       0.0\n",
       "                 2       0.0\n",
       "Name: data norm, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We choose different pairstriples  of dimensions samplesizes and noise level to run the algoirthm for.\n",
    "data_noo_nos = [(12,4500,1e-8),(12,4500,1e-7),(12,4500,1e-6),(12,4500,1e-5),(12,4500,1e-4)\\\n",
    "                ,(12,4500,1e-3),(12,4500,1e-2),(12,4500,1e-1),(12,4500,1)] \n",
    "#                                                       pairs used in simulations in the paper\n",
    "#                                                       uncomment to simulate but is computational intensive\n",
    "data_noo_nos = [(12,4500,1e-2),(12,4500,1e-1),(12,4500,1)] \n",
    "#data_noo_nos = [(8,3000)] #specify pairs to simulate for\n",
    "#runs = 1 #specify number of runs for each pair (10 in the paper)\n",
    "runs = 3\n",
    "max_iter = 30 # specify number of sweeps\n",
    "output = 'data.csv' # specify name of output file\n",
    "\n",
    "# build data structure to store solution\n",
    "tuples = []\n",
    "for data in data_noo_nos:\n",
    "    noo = data[0]\n",
    "    nos = data[1] \n",
    "    sigma = data[2]\n",
    "    for r in range(0,runs):\n",
    "        tuples.append((noo,nos,sigma, r))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['d', 'm','sigma','runs'])           \n",
    "\n",
    "# The results of each optimization is store in a Dataframe\n",
    "col = [\"data norm\", \"noise norm\"]\n",
    "col.extend([i for i in range(1,max_iter+1)])\n",
    "df = pd.DataFrame(np.zeros([len(tuples),max_iter+2]), index=index,columns=col) \n",
    "print(len(index))\n",
    "df[\"data norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2(-1,1) orthogonal polynomials\n",
      "(noo,nos,sigma) = (12,4500,0.01)\n",
      "C1ex frob_norm: 19.885773809434728\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "#loop over all pairs of samples, calls hp.run_als for the solution\n",
    "lam = 1 #regularization parameter\n",
    "#Master iteration\n",
    "psi = hp.basis(0) # get basis functions, Legendre\n",
    "p = len(psi)\n",
    "for data in data_noo_nos:\n",
    "    noo = data[0]\n",
    "    nos = data[1]\n",
    "    sigma = data[2]\n",
    "    print( \"(noo,nos,sigma) = (\" + str(noo) +',' + str(nos) +',' + str(sigma) + ')' )\n",
    "    C2list = hp.build_choice_tensor2(noo) # build selection tensor as list of pxnos matrices\n",
    "    C1ex = exact(noo,p) # construct exact solution\n",
    "    print(\"C1ex frob_norm: \" +str(C1ex.frob_norm()))\n",
    "    for r in range(runs):\n",
    "        [x, y] = hp.fermi_pasta_ulam(noo, nos) # create samples and labels\n",
    "        df[\"data norm\"].loc[(noo,nos,sigma,r)] = np.linalg.norm(y)\n",
    "        noise = np.random.normal(0,sigma,size=y.shape)\n",
    "        df[\"noise norm\"].loc[(noo,nos,sigma,r)] = np.linalg.norm(noise)\n",
    "        y = y + noise\n",
    "        Alist = hp.build_data_tensor_list2(noo,x,nos,psi,p) # build the dictionary tensor for the given samples x\n",
    "        Y = xerus.Tensor.from_ndarray(y)\n",
    "        C1 = initialize(p,noo) # initialize the als randomly\n",
    "        errors = hp.run_als(noo,nos,C1,C2list,Alist,C1ex,Y,max_iter,lam) # run the regularized ALS iteration\n",
    "        #post processing, store data in dataframe\n",
    "        for i in range(1,len(errors)):\n",
    "            df[i].loc[(noo,nos,sigma,r)] = errors[i-1]\n",
    "\n",
    "        print(\"Run: \" +str(r) + \" finished result = \" + str(errors) + \" data norm = \" + str( df[\"data norm\"].loc[(noo,nos,sigma,r)])+ \" noise norm = \" + str( df[\"noise norm\"].loc[(noo,nos,sigma,r)]))\n",
    "        df.to_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
